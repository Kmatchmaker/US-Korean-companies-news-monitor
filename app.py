import streamlit as st
import feedparser
import urllib.parse

# ì„¤ì •: ì£¼ ì´ë¦„ ë§¤í•‘ (í•œêµ­ì–´ ê²€ìƒ‰ìš©)
STATE_MAP = {
    "Georgia": "ì¡°ì§€ì•„",
    "Alabama": "ì•¨ë¼ë°°ë§ˆ",
    "Tennessee": "í…Œë„¤ì‹œ",
    "South Carolina": "ì‚¬ìš°ìŠ¤ìºë¡¤ë¼ì´ë‚˜",
    "Florida": "í”Œë¡œë¦¬ë‹¤"
}

st.set_page_config(page_title="2026 ë¯¸ ë™ë‚¨ë¶€ ê¸°ì—… ëª¨ë‹ˆí„°", layout="wide")

# --- ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜ ---
def fetch_news(query, lang, gl):
    encoded_query = urllib.parse.quote(f"{query} when:30d")
    url = f"https://news.google.com/rss/search?q={encoded_query}&hl={lang}&gl={gl}&ceid={gl}:{lang}"
    feed = feedparser.parse(url)
    return sorted(feed.entries, key=lambda x: x.get('published_parsed', (0,0,0,0,0,0,0,0,0)), reverse=True)

# ==========================================================
# ğŸ‡ºğŸ‡¸ SECTION 1: ë¯¸êµ­ í˜„ì§€ ë‰´ìŠ¤ ë³´ë“œ (US Official News)
# ==========================================================
st.title("ğŸ‡ºğŸ‡¸ ë¯¸êµ­ í˜„ì§€ ì˜¤í”¼ì…œ ë³´ë„")
st.markdown("##### ì£¼ ì •ë¶€ ë° í˜„ì§€ ê²½ì œì§€ì—ì„œ ë³´ë„í•œ ì˜ë¬¸ ê¸°ì‚¬")

cols_us = st.columns(len(STATE_MAP))
for i, (en_name, ko_name) in enumerate(STATE_MAP.items()):
    with cols_us[i]:
        st.info(f"ğŸ“ {en_name}")
        # ë¯¸êµ­ ë‰´ìŠ¤ëŠ” ì˜ì–´ë¡œ ê²€ìƒ‰
        query_us = f'"{en_name}" "South Korea" (investment OR factory OR plant)'
        items = fetch_news(query_us, "en-US", "US")
        
        if not items:
            st.write("ìµœì‹  í˜„ì§€ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        for entry in items[:6]:
            with st.container(border=True):
                st.caption(f"ğŸ“… {entry.published[:16]}")
                st.markdown(f"**[{entry.title.split(' - ')[0]}]({entry.link})**")
                st.caption(f"ì¶œì²˜: {entry.source.title}")

st.divider() # ë³´ë“œ êµ¬ë¶„ì„ ìœ„í•œ êµµì€ ì„ 

# ==========================================================
# ğŸ‡°ğŸ‡· SECTION 2: í•œêµ­ ì–¸ë¡  ë³´ë„ ë³´ë“œ (Korean Media News)
# ==========================================================
st.title("ğŸ‡°ğŸ‡· í•œêµ­ ì–¸ë¡  ë³´ë„")
st.markdown("##### êµ­ë‚´ ì£¼ìš” ì¼ê°„ì§€ ë° ê²½ì œì§€ì—ì„œ ë³´ë„í•œ ì§„ì¶œ ì†Œì‹")

cols_kr = st.columns(len(STATE_MAP))
for i, (en_name, ko_name) in enumerate(STATE_MAP.items()):
    with cols_kr[i]:
        st.success(f"ğŸ“ {ko_name}")
        # [í•µì‹¬ ìˆ˜ì •] í•œêµ­ì–´ ì§€ëª…ìœ¼ë¡œ ê²€ìƒ‰í•˜ì—¬ ì •í™•ë„ ìƒí–¥
        query_kr = f'{ko_name} "ë¯¸êµ­" (íˆ¬ì OR ì§„ì¶œ OR ê³µì¥)'
        items = fetch_news(query_kr, "ko", "KR")
        
        if not items:
            st.write("ê´€ë ¨ í•œêµ­ ë³´ë„ê°€ ì—†ìŠµë‹ˆë‹¤.")
        for entry in items[:6]:
            with st.container(border=True):
                st.caption(f"ğŸ“… {entry.published[:16]}")
                st.markdown(f"**[{entry.title.split(' - ')[0]}]({entry.link})**")
                st.caption(f"ì¶œì²˜: {entry.source.title}")
