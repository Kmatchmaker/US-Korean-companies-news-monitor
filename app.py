import streamlit as st
import feedparser
import urllib.parse
from datetime import datetime

# ì„¤ì •: 5ê°œ ì£¼
STATES = ["Georgia", "Alabama", "Tennessee", "South Carolina", "Florida"]

st.set_page_config(page_title="2026 ë¯¸ ë™ë‚¨ë¶€ éŸ“ ê¸°ì—… ëª¨ë‹ˆí„°", layout="wide")
st.title("ğŸ‡°ğŸ‡· ë¯¸êµ­ ë™ë‚¨ë¶€ ì§„ì¶œ í•œêµ­ ê¸°ì—… ì‹¤ì‹œê°„ ë‰´ìŠ¤ (2026)")

def fetch_news(state):
    # ìµœì‹  ë‰´ìŠ¤ë¥¼ ìœ„í•´ 2026ë…„ í‚¤ì›Œë“œì™€ í•œêµ­ì–´ í‚¤ì›Œë“œë¥¼ í˜¼í•©
    # 'when:7d'ë¥¼ ë¶™ì´ë©´ ìµœê·¼ 7ì¼ ì´ë‚´ ë‰´ìŠ¤ë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    query = f"{state} (í•œêµ­ ê¸°ì—… OR Korean company) investment 2026 when:30d"
    encoded_query = urllib.parse.quote(query)
    
    # êµ¬ê¸€ ë‰´ìŠ¤ RSS (ìµœì‹ ìˆœ ì •ë ¬ ë³´ì •)
    url = f"https://news.google.com/rss/search?q={encoded_query}&hl=ko&gl=KR&ceid=KR:ko"
    
    feed = feedparser.parse(url)
    return feed.entries[:10]

# ëŒ€ì‹œë³´ë“œ êµ¬ì„±
cols = st.columns(len(STATES))

for i, state in enumerate(STATES):
    with cols[i]:
        st.subheader(f"ğŸ“ {state}")
        try:
            news_items = fetch_news(state)
            if not news_items:
                st.write("ìµœê·¼ 30ì¼ ë‚´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            for entry in news_items:
                with st.expander(f"{entry.title[:40]}..."):
                    st.write(f"**{entry.title}**")
                    st.caption(f"ì¶œì²˜: {entry.source.title} | ë‚ ì§œ: {entry.published}")
                    st.markdown(f"[ê¸°ì‚¬ ì½ê¸°]({entry.link})")
        except Exception as e:
            st.error("ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")

st.sidebar.markdown("### ğŸ”” 2026ë…„ 2ì›” ì£¼ìš” í—¤ë“œë¼ì¸")
st.sidebar.write("- **ë™ì›ê¸ˆì†**: ì¡°ì§€ì•„ì£¼ 3,000ë§Œ ë‹¬ëŸ¬ ì‹ ê·œ íˆ¬ì ë°œí‘œ (2/5)")
st.sidebar.write("- **í˜„ëŒ€ì°¨-LG**: ì¡°ì§€ì•„ í•©ì‘ê³µì¥ ì¸ë ¥ ìˆ˜ê¸‰ ë° ê°€ë™ ì¤€ë¹„ ì¤‘")
st.sidebar.write("- **LGì—”ì†”**: ì• ë¦¬ì¡°ë‚˜ ë° ë™ë‚¨ë¶€ LFP ë°°í„°ë¦¬ ë¼ì¸ 2026ë…„ ê°€ë™ ì˜ˆì •")
