import streamlit as st
import feedparser
import urllib.parse
from datetime import datetime

# 1. ëŒ€ìƒ ì£¼ ë° ì •ë°€ ê²€ìƒ‰ì„ ìœ„í•œ ì£¼ìš” ê¸°ì—… ë¦¬ìŠ¤íŠ¸
STATES = ["Georgia", "Alabama", "Tennessee", "South Carolina", "Florida"]
TARGET_COMPANIES = [
    "Hyundai", "Kia", "LG Energy", "SK On", "Samsung SDI", "Hanwha Qcells", 
    "Korea Zinc", "Dongwon", "Ajin", "Seoyon", "Hanon", "Enchem", "NVH Korea"
]

st.set_page_config(page_title="2026 ë¯¸ ë™ë‚¨ë¶€ ê¸°ì—… íˆ¬ì ë¦¬í¬íŠ¸", layout="wide")
st.title("ğŸ­ 2026ë…„ ë¯¸ ë™ë‚¨ë¶€ í•œêµ­ ê¸°ì—… ì§„ì¶œÂ·íˆ¬ì ëª¨ë‹ˆí„°ë§")

def fetch_latest_business_news(state):
    # [ì „ëµ] ê°œë³„ ê¸°ì—…ëª…ê³¼ íˆ¬ì í‚¤ì›Œë“œë¥¼ ì¡°í•©í•˜ì—¬ ì •ë°€ ê²€ìƒ‰
    # when:30dë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœê·¼ 1ê°œì›” ê¸°ì‚¬ë§Œ íƒ€ê²ŸíŒ…
    company_query = " OR ".join([f'"{c}"' for c in TARGET_COMPANIES])
    query = f'{state} ({company_query}) (investment OR factory OR plant OR construction) when:30d'
    
    # í•œêµ­ì–´/ì˜ì–´ ë™ì‹œ ê²€ìƒ‰ì„ ìœ„í•œ ì„¤ì •
    results = []
    configs = [
        {"hl": "ko", "gl": "KR"}, # í•œêµ­ ì–¸ë¡ ì‚¬ ë‰´ìŠ¤
        {"hl": "en", "gl": "US"}  # ë¯¸êµ­ í˜„ì§€ ë³´ë„ìë£Œ ë° ê²½ì œì§€
    ]
    
    for config in configs:
        encoded_query = urllib.parse.quote(query)
        url = f"https://news.google.com/rss/search?q={encoded_query}&hl={config['hl']}&gl={config['gl']}&ceid={config['gl']}:{config['hl']}"
        feed = feedparser.parse(url)
        results.extend(feed.entries)

    # 2. ìµœì‹  ë‚ ì§œ ìˆœìœ¼ë¡œ ê°•ì œ ì •ë ¬ (ì¤‘ìš”!)
    # feedparserì˜ published_parsedë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    results.sort(key=lambda x: x.get('published_parsed', (0,0,0,0,0,0,0,0,0)), reverse=True)

    # 3. ì¤‘ë³µ ì œê±° ë° 2026ë…„ ê¸°ì‚¬ ê²€ì¦
    seen_titles = set()
    final_list = []
    for entry in results:
        title_main = entry.title.split(' - ')[0]
        if title_main not in seen_titles:
            # ì œëª©ì— ëŒ€ê¸°ì—…ì´ë‚˜ íˆ¬ì í‚¤ì›Œë“œê°€ ì‹¤ì œë¡œ ìˆëŠ”ì§€ ì¬ê²€ì¦
            if any(kw.lower() in entry.title.lower() for kw in TARGET_COMPANIES + ["korea"]):
                final_list.append(entry)
                seen_titles.add(title_main)
                
    return final_list[:10] # ê° ì£¼ë³„ ìµœì‹  ë‰´ìŠ¤ 10ê°œì”©

# ëŒ€ì‹œë³´ë“œ í™”ë©´ êµ¬ì„±
cols = st.columns(len(STATES))

for i, state in enumerate(STATES):
    with cols[i]:
        st.subheader(f"ğŸ“ {state}")
        news_items = fetch_latest_business_news(state)
        
        if not news_items:
            st.write("ìµœê·¼ 30ì¼ ë‚´ ì£¼ìš” íˆ¬ì ì†Œì‹ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        for entry in news_items:
            with st.container(border=True):
                # 1. ìµœì‹  ë‚ ì§œ ê°•ì¡° (ê°€ì¥ ìœ„ì— ë°°ì¹˜)
                pub_date = entry.published[:16] # ë‚ ì§œ ë° ì‹œê°„
                st.caption(f"ğŸ“… {pub_date} | {entry.source.title}")
                
                # 2. ê¸°ì‚¬ ì œëª© (ê°œë³„ ê¸°ì—… ì¤‘ì‹¬)
                st.markdown(f"#### [{entry.title.split(' - ')[0]}]({entry.link})")
                
                # 3. ê¸°ì‚¬ ìš”ì•½(ë¯¸ë¦¬ë³´ê¸°)
                if 'summary' in entry:
                    summary = entry.summary.split('<')[0]
                    if len(summary) > 20:
                        st.write(f"ğŸ“ {summary[:150]}...")
