import streamlit as st
import feedparser
import urllib.parse

# 1. 5ê°œ ì£¼ ì„¤ì •
STATES = ["Georgia", "Alabama", "Tennessee", "South Carolina", "Florida"]

# 2. ë‰´ìŠ¤ì—ì„œ ë°˜ë“œì‹œ ìš°ì„ ìˆœìœ„ë¥¼ ë‘˜ í•µì‹¬ ê¸°ì—… ë¦¬ìŠ¤íŠ¸ (ì˜ˆì‹œ)
CORE_COMPANIES = [
    "Hyundai", "Kia", "LG Energy", "SK On", "Samsung SDI", 
    "Hanwha Qcells", "Dongwon", "Ajin", "Seoyon E-Hwa", "Hanon Systems", 
    "Enchem", "NVH Korea", "Zincox", "Korea Zinc", "EcoPro"
]

st.set_page_config(page_title="2026 ë¯¸ ë™ë‚¨ë¶€ ê¸°ì—… íˆ¬ì ëª¨ë‹ˆí„°", layout="wide")
st.title("ğŸ­ í•œêµ­ ê¸°ì—… ì§„ì¶œ ë° ì‹ ê·œ íˆ¬ì ì •ë°€ ë¦¬í¬íŠ¸")

def fetch_business_news(state):
    # [ì „ëµ] ì£¼ ì´ë¦„ + (í•œêµ­ ê¸°ì—… ë¦¬ìŠ¤íŠ¸) + (íˆ¬ì ê´€ë ¨ í•µì‹¬ì–´) ì¡°í•©
    # ê³ ë ¤ì•„ì—°(Korea Zinc), ë™ì›(Dongwon) ë“±ì„ ê²€ìƒ‰ì–´ì— ì§ì ‘ í¬í•¨í•˜ì—¬ ì •í™•ë„ë¥¼ ë†’ì„
    company_query = " OR ".join(CORE_COMPANIES[:10]) # ë„ˆë¬´ ê¸¸ë©´ ì˜¤ë¥˜ë‚˜ë¯€ë¡œ ìƒìœ„ 10ê°œ ìš°ì„ 
    keywords = "(investment OR factory OR plant OR construction OR expansion OR groundbreaking)"
    
    query = f'{state} ("South Korea" OR {company_query}) {keywords} when:30d'
    encoded_query = urllib.parse.quote(query)
    url = f"https://news.google.com/rss/search?q={encoded_query}&hl=en-US&gl=US&ceid=US:en"
    
    feed = feedparser.parse(url)
    
    seen_titles = set()
    filtered_news = []
    
    for entry in feed.entries:
        pure_title = entry.title.split(' - ')[0]
        if pure_title not in seen_titles:
            # ì œëª©ì— í•œêµ­ ê´€ë ¨ í˜¹ì€ ì‚°ì—… í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ ìµœì¢… ê²€ì¦
            title_lower = entry.title.lower()
            if any(word.lower() in title_lower for word in CORE_COMPANIES + ["korea", "invest"]):
                filtered_news.append(entry)
                seen_titles.add(pure_title)
                
    return filtered_news[:6]

# ëŒ€ì‹œë³´ë“œ í™”ë©´ êµ¬ì„±
cols = st.columns(len(STATES))

for i, state in enumerate(STATES):
    with cols[i]:
        st.subheader(f"ğŸ“ {state}")
        news_items = fetch_business_news(state)
        
        if not news_items:
            st.write("ê´€ë ¨ëœ ì‹ ê·œ íˆ¬ì ì†Œì‹ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        for entry in news_items:
            with st.container(border=True):
                # ì¶œì²˜ ë° ë‚ ì§œ
                st.caption(f"ğŸ“… {entry.published[:16]} | {entry.source.title}")
                
                # ì œëª© (í´ë¦­ ì‹œ ì›ë¬¸)
                st.markdown(f"#### [{entry.title.split(' - ')[0]}]({entry.link})")
                
                # ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸° (ìš”ì•½ ëŒ€ìš©)
                if 'summary' in entry:
                    # HTML íƒœê·¸ë¥¼ ì œê±°í•˜ê³  ì‹¤ì œ ë‚´ìš©ë§Œ ì¶”ì¶œ
                    clean_summary = entry.summary.split('<')[0]
                    if len(clean_summary) > 20:
                        st.write(f"ğŸ” {clean_summary[:180]}...")
                    else:
                        st.write("ğŸ” ìƒì„¸ ë‚´ìš©ì€ ê¸°ì‚¬ ì›ë¬¸ì„ í™•ì¸í•˜ì„¸ìš”.")
