import streamlit as st
import feedparser
import urllib.parse
from datetime import datetime

# ì„¤ì •: 5ê°œ ì£¼
STATES = ["Georgia", "Alabama", "Tennessee", "South Carolina", "Florida"]

st.set_page_config(page_title="2026 ë¯¸ ë™ë‚¨ë¶€ ê¸°ì—… íˆ¬ì ëª¨ë‹ˆí„°", layout="wide")
st.title("ğŸ“Š ë¯¸ ë™ë‚¨ë¶€ í•œêµ­ ê¸°ì—… ì§„ì¶œ ì´ì›í™” ëª¨ë‹ˆí„°ë§")

# --- ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜ ---
def fetch_news(query, lang="en-US", gl="US"):
    encoded_query = urllib.parse.quote(f"{query} when:30d")
    url = f"https://news.google.com/rss/search?q={encoded_query}&hl={lang}&gl={gl}&ceid={gl}:{lang}"
    feed = feedparser.parse(url)
    # ìµœì‹ ìˆœ ì •ë ¬
    entries = sorted(feed.entries, key=lambda x: x.get('published_parsed', (0,0,0,0,0,0,0,0,0)), reverse=True)
    return entries

# --- í™”ë©´ ë ˆì´ì•„ì›ƒ (Tabs) ---
tab_us, tab_kr = st.tabs(["ğŸ‡ºğŸ‡¸ ë¯¸êµ­ í˜„ì§€ ì˜¤í”¼ì…œ ë³´ë„ (Gov/Local News)", "ğŸ‡°ğŸ‡· í•œêµ­ ì–¸ë¡  ë³´ë„ (Korean Media)"])

# --- TAB 1: ë¯¸êµ­ í˜„ì§€ ë³´ë„ ---
with tab_us:
    st.info("ğŸ’¡ ì£¼ ì •ë¶€ ë°œí‘œìë£Œ ë° ë¯¸êµ­ í˜„ì§€ ì–¸ë¡ ì˜ ì˜¤í”¼ì…œ ë¦¬í¬íŠ¸ì…ë‹ˆë‹¤.")
    cols = st.columns(len(STATES))
    for i, state in enumerate(STATES):
        with cols[i]:
            st.subheader(f"ğŸ“ {state}")
            # ì£¼ ì •ë¶€ ë° íˆ¬ì ê´€ë ¨ ì˜ì–´ í‚¤ì›Œë“œ ê²€ìƒ‰
            query = f'site:.gov OR site:.org "{state}" "South Korea" investment factory'
            news_items = fetch_news(query)
            
            if not news_items: st.write("ìµœê·¼ ì†Œì‹ì´ ì—†ìŠµë‹ˆë‹¤.")
            for entry in news_items[:6]:
                with st.container(border=True):
                    st.caption(f"ğŸ“… {entry.published[:16]} | {entry.source.title}")
                    st.markdown(f"**[{entry.title.split(' - ')[0]}]({entry.link})**")

# --- TAB 2: í•œêµ­ ì–¸ë¡  ë³´ë„ ---
with tab_kr:
    st.success("ğŸ’¡ í•œêµ­ ë‚´ ì£¼ìš” ì–¸ë¡ ì‚¬ê°€ ë³´ë„í•˜ëŠ” ë¯¸êµ­ ì§„ì¶œ ê¸°ì—… ì†Œì‹ì…ë‹ˆë‹¤.")
    cols = st.columns(len(STATES))
    for i, state in enumerate(STATES):
        with cols[i]:
            st.subheader(f"ğŸ“ {state}")
            # í•œêµ­ì–´ í‚¤ì›Œë“œ ê²€ìƒ‰
            query = f'{state} "ë¯¸êµ­ ì§„ì¶œ" OR "íˆ¬ì" OR "ê³µì¥"'
            news_items = fetch_news(query, lang="ko", gl="KR")
            
            if not news_items: st.write("ìµœê·¼ ì†Œì‹ì´ ì—†ìŠµë‹ˆë‹¤.")
            for entry in news_items[:6]:
                with st.container(border=True):
                    st.caption(f"ğŸ“… {entry.published[:16]} | {entry.source.title}")
                    st.markdown(f"**[{entry.title.split(' - ')[0]}]({entry.link})**")
