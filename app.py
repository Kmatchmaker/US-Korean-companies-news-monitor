import streamlit as st
import feedparser
import urllib.parse
from datetime import datetime

# 1. ëŒ€ìƒ ì£¼ ë° ì‚°ì—…ë³„ í•µì‹¬ í‚¤ì›Œë“œ (ê°€ì¤‘ì¹˜ ë¶€ì—¬)
STATES = {
    "Georgia": "ì¡°ì§€ì•„ (í˜„ëŒ€ì°¨Â·ë™ì›Â·ë•ì‹  ë“±)",
    "Alabama": "ì•¨ë¼ë°°ë§ˆ (GMBì½”ë¦¬ì•„Â·ë¶€í’ˆì‚¬ ë“±)",
    "Tennessee": "í…Œë„¤ì‹œ (LGì—”ì†”Â·í•œêµ­íƒ€ì´ì–´ ë“±)",
    "South Carolina": "ì‚¬ìš°ìŠ¤ìºë¡¤ë¼ì´ë‚˜ (ì „ë ¥ê¸°ê¸°Â·ì‚¼ì„± ë“±)",
    "Florida": "í”Œë¡œë¦¬ë‹¤ (ì‹ ì—ë„ˆì§€Â·ë¬¼ë¥˜ ë“±)"
}

st.set_page_config(page_title="2026 éŸ“ ê¸°ì—… ë¯¸êµ­ ì§„ì¶œ ì‹¤ì‹œê°„ ë³´ë“œ", layout="wide")
st.title("ğŸš€ 2026ë…„ 2ì›” ë¯¸ ë™ë‚¨ë¶€ éŸ“ ê¸°ì—… ì§„ì¶œÂ·íˆ¬ì ì¸í…”ë¦¬ì „ìŠ¤")
st.caption("ì£¼ ì •ë¶€ ê³µì‹ ë°œí‘œ ë° í•µì‹¬ ê²½ì œì§€ì˜ 'ì„±ì¥Â·íˆ¬ì' ë‰´ìŠ¤ë§Œ ì„ ë³„ ë¸Œë¦¬í•‘í•©ë‹ˆë‹¤.")

# --- ê³ ì •ë°€ ë‰´ìŠ¤ ìˆ˜ì§‘ ì—”ì§„ (ê¸°ì—… ì„±ì¥ í‚¤ì›Œë“œ íŠ¹í™”) ---
def fetch_biz_centric_news(query, lang, gl):
    # 2026ë…„ 2ì›” ì´í›„ + ë¹„ì¦ˆë‹ˆìŠ¤ í™•ì¥ í‚¤ì›Œë“œ ê°•ì œ ê²°í•©
    biz_terms = '(investment OR "new plant" OR expansion OR "breaking ground" OR "capital increase" OR "official announcement")'
    date_filter = "after:2026-02-01"
    
    full_query = f'{query} {biz_terms} {date_filter}'
    encoded_query = urllib.parse.quote(full_query)
    url = f"https://news.google.com/rss/search?q={encoded_query}&hl={lang}&gl={gl}&ceid={gl}:{lang}"
    
    feed = feedparser.parse(url)
    verified = []
    
    # ë…¸ì´ì¦ˆ í•„í„° (êµ¬ê¸ˆ, ë ˆì´ë“œ, ì‚¬ê±´ ë“± ë¶€ì • í‚¤ì›Œë“œ ì œëª©ì—ì„œ ë°œê²¬ ì‹œ ì¦‰ì‹œ ì œì™¸)
    noise_words = ["arrest", "raid", "detain", "police", "investigation", "êµ¬ê¸ˆ", "ë ˆì´ë“œ", "ìˆ˜ì‚¬"]
    
    for entry in feed.entries:
        title = entry.title.lower()
        if entry.get('published_parsed') and entry.published_parsed.tm_year == 2026:
            if not any(noise in title for noise in noise_words):
                verified.append(entry)
                
    return sorted(verified, key=lambda x: x.get('published_parsed'), reverse=True)

# --- í™”ë©´ êµ¬ì„±: ê³µì‹ ë ¥ ìˆëŠ” ë°ì´í„° ë³´ë“œ ---
tab_us, tab_kr = st.tabs(["ğŸ‡ºğŸ‡¸ ë¯¸êµ­ í˜„ì§€ ì˜¤í”¼ì…œ (Gov & Biz Media)", "ğŸ‡°ğŸ‡· í•œêµ­ ì–¸ë¡  & ê³µì‹œ (Domestic Press)"])

with tab_us:
    st.info("ğŸ›ï¸ ë¯¸êµ­ ì£¼ ì •ë¶€(Official) ë° í˜„ì§€ ê²½ì œì§€ ë°œ 'ì‹ ê·œ íˆ¬ì/ì¦ì„¤' ì†Œì‹")
    for en_name, display_name in STATES.items():
        st.markdown(f"#### ğŸ“ {display_name}")
        gov_col, biz_col = st.columns(2)
        
        with gov_col:
            st.caption("ğŸ›ï¸ 1. ì£¼ ì •ë¶€ ë³´ë„ìë£Œ (site:.gov)")
            # ì£¼ ì •ë¶€ ê³µì‹ í”„ë ˆìŠ¤ë£¸ ë° ê²½ì œê°œë°œêµ­(GDEcD ë“±) íƒ€ê²ŸíŒ…
            q = f'site:.gov "{en_name}" ("South Korea" OR Korean) investment'
            items = fetch_biz_centric_news(q, "en-US", "US")
            if not items: st.write(":grey[ì‹ ê·œ ê³µì‹ ë°œí‘œ ëŒ€ê¸° ì¤‘]")
            for e in items[:5]:
                with st.container(border=True):
                    st.markdown(f"**[{e.title.split(' - ')[0]}]({e.link})**")
                    st.caption(f"ğŸ“… {e.published[:16]}")
        
        with biz_col:
            st.caption("ğŸ“° 2. í˜„ì§€ í•µì‹¬ ê²½ì œì§€ (Biz Journals, AJC ë“±)")
            # 'Journal', 'Chronicle' ë“± ë¡œì»¬ ê²½ì œ ì „ë¬¸ ë§¤ì²´ ê°€ì¤‘ì¹˜
            q = f'"{en_name}" "South Korea" (Journal OR Chronicle OR News) investment'
            items = fetch_biz_centric_news(q, "en-US", "US")
            for e in items[:5]:
                with st.container(border=True):
                    st.markdown(f"**[{e.title.split(' - ')[0]}]({e.link})**")
                    st.caption(f"ğŸ“… {e.published[:16]} | {e.source.title}")

with tab_kr:
    st.success("ğŸ—ï¸ í•œêµ­ ì£¼ìš” ê²½ì œì§€ ë° ê¸°ì—… ê³µì‹œ ê¸°ë°˜ íˆ¬ì ë³´ë„")
    for en_name, display_name in STATES.items():
        ko_name = display_name.split(" ")[0]
        st.markdown(f"#### ğŸ“ {ko_name} ({en_name})")
        press_col, diaspora_col = st.columns(2)
        
        with press_col:
            st.caption("ğŸ—ï¸ 1. í•œêµ­ ì£¼ìš” ì–¸ë¡  (íˆ¬ì/ìˆ˜ì£¼/ì¦ì„¤)")
            # ì‚¬ìš©ì ìš”ì²­ í‚¤ì›Œë“œ (ì¶œì, ì¦ì„¤, ë³€ì••ê¸°, ì–‘ì‚° ë“±) ë°˜ì˜
            q = f'{ko_name} ("ì¶œì" OR "ì¦ì„¤" OR "ì–‘ì‚°" OR "ìˆ˜ì£¼" OR "ë³€ì••ê¸°")'
            items = fetch_biz_centric_news(q, "ko", "KR")
            for e in items[:6]:
                with st.container(border=True):
                    st.markdown(f"**[{e.title.split(' - ')[0]}]({e.link})**")
                    st.caption(f"ğŸ“… {e.published[:16]} | {e.source.title}")
                    
        with diaspora_col:
            st.caption("ğŸ‡ºğŸ‡¸ 2. ë¯¸ í˜„ì§€ ë™í¬ ê²½ì œ ì†Œì‹")
            q = f'{ko_name} (íˆ¬ì OR ê³µì¥ OR ì§„ì¶œ)'
            items = fetch_biz_centric_news(q, "ko", "US")
            for e in items[:6]:
                with st.container(border=True):
                    st.markdown(f"**[{e.title.split(' - ')[0]}]({e.link})**")
                    st.caption(f"ğŸ“… {e.published[:16]} | {e.source.title}")
