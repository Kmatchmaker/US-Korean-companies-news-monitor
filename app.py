import streamlit as st
import feedparser
import urllib.parse
from datetime import datetime

# 1. ì£¼ë³„ ê²€ìƒ‰ì–´ ìµœì í™” (ë°ì´í„° ì„ì„ ë°©ì§€ ë¡œì§ ê°•í™”)
# 'site:.gov'ë‚˜ ì§€ì—­ ì–¸ë¡ ì‚¬ë¥¼ ìš°ì„ í•˜ë„ë¡ ê²€ìƒ‰ì–´ë¥¼ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.
STATE_QUERIES = {
    "Georgia": 'Georgia ("South Korea" OR Korean) (investment OR factory OR "new plant") when:30d',
    "Alabama": 'Alabama ("South Korea" OR Korean) (investment OR factory OR "new plant") when:30d',
    "Tennessee": 'Tennessee ("South Korea" OR Korean) (investment OR factory OR "new plant") when:30d',
    "South Carolina": '"South Carolina" ("South Korea" OR Korean) (investment OR factory OR "new plant") when:30d',
    "Florida": 'Florida ("South Korea" OR Korean) (investment OR factory OR "new plant") when:30d'
}

st.set_page_config(page_title="2026 ë¯¸ ë™ë‚¨ë¶€ éŸ“ ê¸°ì—… íˆ¬ì í˜„í™©", layout="wide")
st.title("ğŸšœ 2026ë…„ ë¯¸ ë™ë‚¨ë¶€ í•œêµ­ ê¸°ì—… ì§„ì¶œÂ·íˆ¬ì ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§")
st.markdown("---")

def fetch_and_clean_news(state_name):
    query = STATE_QUERIES.get(state_name)
    encoded_query = urllib.parse.quote(query)
    
    # ì˜ì–´(í˜„ì§€ ë³´ë„)ì™€ í•œêµ­ì–´(êµ­ë‚´ ë³´ë„) ê²°ê³¼ë¥¼ ëª¨ë‘ ê°€ì ¸ì™€ í†µí•©í•©ë‹ˆë‹¤.
    news_feeds = [
        f"https://news.google.com/rss/search?q={encoded_query}&hl=en-US&gl=US&ceid=US:en",
        f"https://news.google.com/rss/search?q={encoded_query}&hl=ko&gl=KR&ceid=KR:ko"
    ]
    
    all_entries = []
    for url in news_feeds:
        feed = feedparser.parse(url)
        all_entries.extend(feed.entries)
    
    # 2. ìµœì‹  ë‚ ì§œ ìˆœ ì •ë ¬ (ê°•ì œ ì •ë ¬)
    all_entries.sort(key=lambda x: x.get('published_parsed', (0,0,0,0,0,0,0,0,0)), reverse=True)
    
    # 3. ì¤‘ë³µ ì œê±° ë° 'ê·¸ ì£¼' ë‰´ìŠ¤ê°€ ë§ëŠ”ì§€ êµì°¨ ê²€ì¦
    unique_news = []
    seen_titles = set()
    
    for entry in all_entries:
        pure_title = entry.title.split(' - ')[0].strip()
        # ë°ì´í„° ì„ì„ ë°©ì§€: ì œëª©ì´ë‚˜ ë§í¬ì— í•´ë‹¹ ì£¼ ì´ë¦„ì´ í¬í•¨ë˜ì–´ì•¼ í•¨
        if state_name.lower() in entry.title.lower() or state_name.lower().replace(" ", "") in entry.link.lower():
            if pure_title not in seen_titles:
                # 2024ë…„ ì´ì „ ë…¸í›„ ê¸°ì‚¬ ë°°ì œ (í•œ ë²ˆ ë” í•„í„°ë§)
                if "2024" not in entry.title and "2023" not in entry.title:
                    unique_news.append(entry)
                    seen_titles.add(pure_title)
                
    return unique_news[:8]

# 4. ëŒ€ì‹œë³´ë“œ í™”ë©´ êµ¬ì„±
cols = st.columns(len(STATE_QUERIES))

for i, state in enumerate(STATE_QUERIES.keys()):
    with cols[i]:
        st.subheader(f"ğŸ“ {state}")
        news_items = fetch_and_clean_news(state)
        
        if not news_items:
            st.write("âœ… ì‹ ê·œ ì†Œì‹ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        for entry in news_items:
            with st.container(border=True):
                # ìµœì‹  ë‚ ì§œ ë° ì–¸ë¡ ì‚¬
                st.caption(f"ğŸ“… {entry.published[:16]} | {entry.source.title}")
                # ì œëª© (í´ë¦­ ì‹œ ì›ë¬¸ ì´ë™)
                st.markdown(f"#### [{entry.title.split(' - ')[0]}]({entry.link})")
                
                # ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸° (í•µì‹¬ ë‚´ìš© íŒŒì•…)
                if 'summary' in entry:
                    # HTML íƒœê·¸ ì œê±° ë° í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
                    clean_summary = entry.summary.split('<')[0]
                    if len(clean_summary) > 10:
                        st.write(f"ğŸ“ {clean_summary[:150]}...")
