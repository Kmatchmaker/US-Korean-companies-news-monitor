import streamlit as st
import feedparser
import urllib.parse
from datetime import datetime

# 1. ì„¤ì •: ì£¼ë³„ ë§¤í•‘
STATES_INFO = {
    "Georgia": "ì¡°ì§€ì•„",
    "Alabama": "ì•¨ë¼ë°°ë§ˆ",
    "Tennessee": "í…Œë„¤ì‹œ",
    "South Carolina": "ì‚¬ìš°ìŠ¤ìºë¡¤ë¼ì´ë‚˜",
    "Florida": "í”Œë¡œë¦¬ë‹¤"
}

st.set_page_config(page_title="2026 ë¯¸ ë™ë‚¨ë¶€ ê¸°ì—… ëª¨ë‹ˆí„°", layout="wide")
st.title("ğŸ›ï¸ 2026ë…„ 2ì›” ë¯¸ ë™ë‚¨ë¶€ ì§„ì¶œ ê¸°ì—… ì •ë°€ ëª¨ë‹ˆí„°ë§")
st.caption(f"ê²€ìƒ‰ ê¸°ì¤€ì¼: 2026-02-01 ì´í›„ ê¸°ì‚¬ë§Œ ìˆ˜ì§‘ (2025ë…„ ì´ì „ ê¸°ì‚¬ ê°•ì œ ì°¨ë‹¨)")

# --- ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ì—„ê²©í•œ ë‚ ì§œ í•„í„° í•¨ìˆ˜ ---
def fetch_verified_news(query, lang, gl):
    # ì¿¼ë¦¬ì— ë‚ ì§œë¥¼ ëª…ì‹œí•˜ì—¬ êµ¬ê¸€ ê²€ìƒ‰ ë‹¨ê³„ì—ì„œ ê³¼ê±° ê¸°ì‚¬ ì°¨ë‹¨
    precise_query = f"{query} after:2026-02-01"
    encoded_query = urllib.parse.quote(precise_query)
    url = f"https://news.google.com/rss/search?q={encoded_query}&hl={lang}&gl={gl}&ceid={gl}:{lang}"
    
    feed = feedparser.parse(url)
    verified_entries = []
    
    for entry in feed.entries:
        # [2ì¤‘ ê²€ì¦] ê¸°ì‚¬ ë°œí–‰ì¼ì˜ ì—°ë„ê°€ 2026ë…„ì¸ì§€ ë‹¤ì‹œ í™•ì¸
        if entry.get('published_parsed') and entry.published_parsed.tm_year == 2026:
            verified_entries.append(entry)
            
    # ìµœì‹  ë‚ ì§œìˆœìœ¼ë¡œ ì •ë ¬
    return sorted(verified_entries, key=lambda x: x.get('published_parsed'), reverse=True)

# --- í™”ë©´ êµ¬ì„± ---
tab_us, tab_kr = st.tabs(["ğŸ‡ºğŸ‡¸ ë¯¸êµ­ í˜„ì§€ ë‰´ìŠ¤ (Gov/Local/Major)", "ğŸ‡°ğŸ‡· í•œêµ­ ë° ë™í¬ ë‰´ìŠ¤ (Press/Diaspora)"])

# ë³´ë“œ A: ë¯¸êµ­ í˜„ì§€ ë‰´ìŠ¤ (ì£¼ì •ë¶€/ì§€ì—­ì§€/ë©”ì´ì €)
with tab_us:
    for en_name, ko_name in STATES_INFO.items():
        st.markdown(f"### ğŸ“ {en_name} ({ko_name})")
        gov_col, local_col, major_col = st.columns(3)
        
        with gov_col:
            st.caption("ğŸ›ï¸ 1. ì£¼ ì •ë¶€ (.gov)")
            items = fetch_verified_news(f'site:.gov "{en_name}" "South Korea" investment', "en-US", "US")
            for entry in items[:3]:
                with st.container(border=True):
                    st.markdown(f"**[{entry.title.split(' - ')[0]}]({entry.link})**")
                    st.caption(f"ğŸ“… {entry.published[:16]}")
        
        with local_col:
            st.caption("ğŸ“° 2. ì£¼ë³„ ì§€ì—­ ì‹ ë¬¸")
            items = fetch_verified_news(f'"{en_name}" "South Korea" investment (journal OR gazette OR times)', "en-US", "US")
            for entry in items[:3]:
                with st.container(border=True):
                    st.markdown(f"**[{entry.title.split(' - ')[0]}]({entry.link})**")
                    st.caption(f"ğŸ“… {entry.published[:16]} | {entry.source.title}")

        with major_col:
            st.caption("ğŸŒ 3. ë©”ì´ì € ë‰´ìŠ¤")
            items = fetch_verified_news(f'"{en_name}" "South Korea" investment (Bloomberg OR Reuters OR AP)', "en-US", "US")
            for entry in items[:3]:
                with st.container(border=True):
                    st.markdown(f"**[{entry.title.split(' - ')[0]}]({entry.link})**")
                    st.caption(f"ğŸ“… {entry.published[:16]} | {entry.source.title}")

# ë³´ë“œ B: í•œêµ­ ë° ë™í¬ ë‰´ìŠ¤ (êµ­ë‚´ ì£¼ìš” ì–¸ë¡ /ë™í¬ ì‹ ë¬¸)
with tab_kr:
    for en_name, ko_name in STATES_INFO.items():
        st.markdown(f"### ğŸ“ {ko_name} ({en_name}) ë³´ë„")
        main_press_col, diaspora_col = st.columns(2)
        
        with main_press_col:
            st.caption("ğŸ—ï¸ 1. í•œêµ­ ì£¼ìš” ì–¸ë¡ ì‚¬ (ê²½ì œì§€/ì¼ê°„ì§€)")
            # êµ­ë‚´ ì£¼ìš” ì–¸ë¡ ì‚¬ íƒ€ê²ŸíŒ… (ì •í™•ë„ë¥¼ ìœ„í•´ ì£¼ ì´ë¦„ì„ í•œêµ­ì–´ë¡œ ê²€ìƒ‰)
            q_main = f'{ko_name} "ë¯¸êµ­" (íˆ¬ì OR ì§„ì¶œ OR ê³µì¥)'
            items = fetch_verified_news(q_main, "ko", "KR")
            for entry in items[:5]:
                with st.container(border=True):
                    st.markdown(f"**[{entry.title.split(' - ')[0]}]({entry.link})**")
                    st.caption(f"ğŸ“… {entry.published[:16]} | {entry.source.title}")

        with diaspora_col:
            st.caption("ğŸ‡ºğŸ‡¸ 2. ë¯¸ í˜„ì§€ ë™í¬ ì‹ ë¬¸ (í•œì¸ ë‰´ìŠ¤)")
            # ë¯¸ í˜„ì§€ ë™í¬ ì‹ ë¬¸(ì¤‘ì•™ì¼ë³´USA, í•œêµ­ì¼ë³´USA, ì• í‹€ëœíƒ€K ë“±) íƒ€ê²ŸíŒ…
            # ë¯¸êµ­ ë‚´ í•œêµ­ì–´ ê²€ìƒ‰(gl=US)ì„ í†µí•´ ë™í¬ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
            q_dia = f'{ko_name} "íˆ¬ì" OR "ê³µì¥" OR "ì§„ì¶œ"'
            items = fetch_verified_news(q_dia, "ko", "US")
            for entry in items[:5]:
                with st.container(border=True):
                    st.markdown(f"**[{entry.title.split(' - ')[0]}]({entry.link})**")
                    st.caption(f"ğŸ“… {entry.published[:16]} | {entry.source.title}")
