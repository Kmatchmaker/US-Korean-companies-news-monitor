import streamlit as st
import feedparser
import urllib.parse  # ì£¼ì†Œ ì˜¤ë¥˜ ìˆ˜ì •ì„ ìœ„í•´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.

# ì„¤ì •: 5ê°œ ì£¼
STATES = ["Georgia", "Alabama", "Tennessee", "South Carolina", "Florida"]

st.set_page_config(page_title="ë¯¸êµ­ ë™ë‚¨ë¶€ í•œêµ­ê¸°ì—… ë‰´ìŠ¤ ì„¼í„°", layout="wide")
st.title("ğŸ‡°ğŸ‡· ë¯¸êµ­ ë™ë‚¨ë¶€ ì§„ì¶œ í•œêµ­ ê¸°ì—… ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§")
st.sidebar.info("2026ë…„ ì‹ ê·œ ì§„ì… ë° ì£¼ìš” ê¸°ì—… ë‰´ìŠ¤ë¥¼ ë§¤ì¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.")

def fetch_news(state):
    # ê²€ìƒ‰ì–´ ì„¤ì •
    query = f"{state} South Korea investment factory"
    
    # [ìˆ˜ì • í¬ì¸íŠ¸] ê²€ìƒ‰ì–´ ì‚¬ì´ì˜ ê³µë°±ì„ ì•ˆì „í•˜ê²Œ ë³€í™˜í•©ë‹ˆë‹¤.
    encoded_query = urllib.parse.quote(query)
    url = f"https://news.google.com/rss/search?q={encoded_query}&hl=en-US&gl=US&ceid=US:en"
    
    feed = feedparser.parse(url)
    return feed.entries[:8]

# ëŒ€ì‹œë³´ë“œ í™”ë©´ êµ¬ì„±
cols = st.columns(len(STATES))

for i, state in enumerate(STATES):
    with cols[i]:
        st.header(f"ğŸ“ {state}")
        try:
            news_items = fetch_news(state)
            if not news_items:
                st.write("ìƒˆë¡œìš´ ì†Œì‹ì´ ì—†ìŠµë‹ˆë‹¤.")
            for entry in news_items:
                with st.container():
                    st.markdown(f"**[{entry.source.title}]**")
                    st.write(f"[{entry.title}]({entry.link})")
                    st.caption(f"ë°œí–‰ì¼: {entry.published[:16]}")
                    st.divider()
        except Exception as e:
            st.error(f"ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
