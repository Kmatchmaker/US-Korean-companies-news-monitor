import streamlit as st
import feedparser
import urllib.parse
from datetime import datetime

# 1. ëŒ€ìƒ ì£¼ ì„¤ì •
STATES_MAP = {
    "Georgia": "ì¡°ì§€ì•„",
    "Alabama": "ì•¨ë¼ë°°ë§ˆ",
    "Tennessee": "í…Œë„¤ì‹œ",
    "South Carolina": "ì‚¬ìš°ìŠ¤ìºë¡¤ë¼ì´ë‚˜",
    "Florida": "í”Œë¡œë¦¬ë‹¤"
}

st.set_page_config(page_title="2026 ë¯¸ ë™ë‚¨ë¶€ éŸ“ ê¸°ì—… ì§„ì¶œ ëª¨ë‹ˆí„°", layout="wide")
st.title("ğŸšœ 2026ë…„ ë¯¸ ë™ë‚¨ë¶€ í•œêµ­ ê¸°ì—… ì‹ ê·œ ì§„ì¶œÂ·íˆ¬ì ì „ìˆ˜ ê°ì‹œ")
st.caption("2026ë…„ 2ì›” 1ì¼ ì´í›„ ë°œí‘œëœ ëª¨ë“  í•œêµ­ ê¸°ì—…ì˜ ë¯¸êµ­ í˜„ì§€ íˆ¬ì/ê³µì¥ ì„¤ë¦½ ì†Œì‹ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")

# --- ì „ë°©ìœ„ ìˆ˜ì§‘ ë° ë‚ ì§œ/ë‚´ìš© ì •ë°€ ê²€ì¦ í•¨ìˆ˜ ---
def fetch_all_korean_investments(query, lang, gl):
    # ë‚ ì§œ í•„í„°: 2026ë…„ 2ì›” 1ì¼ ì´í›„ (ê³¼ê±° ë‰´ìŠ¤ ì°¨ë‹¨)
    date_filter = "after:2026-02-01"
    # [í•µì‹¬ í•„í„°] 'í•œêµ­' ê´€ë ¨ í‚¤ì›Œë“œì™€ 'ë¹„ì¦ˆë‹ˆìŠ¤ í™•ì¥' í‚¤ì›Œë“œ ì „ë°©ìœ„ ê²°í•©
    # íŠ¹ì • ê¸°ì—…ëª…ì´ ì•„ë‹Œ 'Korean company', 'South Korea investment' ë“±ìœ¼ë¡œ í¬ê´„ ê²€ìƒ‰
    full_query = f'({query}) ("South Korea" OR Korean OR "í•œêµ­ ê¸°ì—…" OR "ì§„ì¶œ") (investment OR factory OR plant OR "announces") {date_filter}'
    
    encoded_query = urllib.parse.quote(full_query)
    url = f"https://news.google.com/rss/search?q={encoded_query}&hl={lang}&gl={gl}&ceid={gl}:{lang}"
    
    feed = feedparser.parse(url)
    verified_results = []
    
    for entry in feed.entries:
        # [2ì¤‘ ê²€ì¦] 2026ë…„ ë‰´ìŠ¤ë§Œ í†µê³¼
        if entry.get('published_parsed') and entry.published_parsed.tm_year == 2026:
            verified_results.append(entry)
                
    # ìµœì‹  ë‚ ì§œìˆœ ì •ë ¬
    return sorted(verified_results, key=lambda x: x.get('published_parsed'), reverse=True)

# --- ë³´ë“œ êµ¬ì„±: 1. ë¯¸êµ­ ê³µì‹ ë ¥ ì†ŒìŠ¤ / 2. í•œêµ­/ë™í¬ ê³µì‹ ë ¥ ì†ŒìŠ¤ ---
tab_us, tab_kr = st.tabs(["ğŸ‡ºğŸ‡¸ ë¯¸êµ­ í˜„ì§€ ì˜¤í”¼ì…œ ë³´ë“œ", "ğŸ‡°ğŸ‡· í•œêµ­ ì–¸ë¡  ë° í˜„ì§€ ë™í¬ ë³´ë“œ"])

with tab_us:
    st.info("ğŸ’¡ ì£¼ ì •ë¶€(Governor's Office) ë°œí‘œ ë° ë¯¸êµ­ ê²½ì œ ì „ë¬¸ì§€ ë¦¬í¬íŠ¸")
    for en_name, ko_name in STATES_MAP.items():
        with st.expander(f"ğŸ“ {en_name} ({ko_name}) - í˜„ì§€ ë°œ ì†Œì‹", expanded=True):
            col1, col2, col3 = st.columns(3)
            
            with col1: # 1. ì£¼ ì •ë¶€ ë° ê²½ì œêµ­ ê³µì‹ ë°œí‘œ
                st.caption("ğŸ›ï¸ ì£¼ ì •ë¶€/ê²½ì œêµ­ (.gov)")
                # 'site:.gov'ë¥¼ í†µí•´ ì¡°ì§€ì•„ ì£¼ì§€ì‚¬ ë°œí‘œ ê°™ì€ 1ìˆœìœ„ ì˜¤í”¼ì…œ ë‰´ìŠ¤ í¬ì°©
                q = f'site:.gov "{en_name}" "South Korea"'
                items = fetch_all_korean_investments(q, "en-US", "US")
                for e in items[:5]:
                    with st.container(border=True):
                        st.markdown(f"**[{e.title.split(' - ')[0]}]({e.link})**")
                        st.caption(f"ğŸ“… {e.published[:16]}")
            
            with col2: # 2. ì£¼ë³„ ë¡œì»¬ ê²½ì œì§€
                st.caption("ğŸ“° ì§€ì—­ ê²½ì œ ë§¤ì²´ (Business Journal ë“±)")
                q = f'"{en_name}" "South Korea" investment'
                items = fetch_all_korean_investments(q, "en-US", "US")
                for e in items[:5]:
                    with st.container(border=True):
                        st.markdown(f"**[{e.title.split(' - ')[0]}]({e.link})**")
                        st.caption(f"ğŸ“… {e.published[:16]} | {e.source.title}")

            with col3: # 3. ë©”ì´ì €/ê¸€ë¡œë²Œ ê²½ì œì§€
                st.caption("ğŸŒ ë©”ì´ì € ì–¸ë¡  (Reuters/Bloomberg)")
                q = f'"{en_name}" "South Korea" (investment OR factory)'
                items = fetch_all_korean_investments(q, "en-US", "US")
                for e in items[:3]:
                    with st.container(border=True):
                        st.markdown(f"**[{e.title.split(' - ')[0]}]({e.link})**")
                        st.caption(f"ğŸ“… {e.published[:16]} | {e.source.title}")

with tab_kr:
    st.success("ğŸ’¡ í•œêµ­ ë‚´ ì£¼ìš” ì–¸ë¡  ë° ë¯¸êµ­ í˜„ì§€ í•œì¸ ë™í¬ ì‹ ë¬¸ ë³´ë„")
    for en_name, ko_name in STATES_MAP.items():
        with st.expander(f"ğŸ“ {ko_name} ({en_name}) - í•œêµ­ì–´ ë³´ë„", expanded=True):
            col_press, col_diaspora = st.columns(2)
            
            with col_press: # 1. í•œêµ­ ì£¼ìš” ì–¸ë¡  (ë„¤ì´ë²„ ë‰´ìŠ¤ ë“±)
                st.caption("ğŸ—ï¸ í•œêµ­ ì£¼ìš” ì–¸ë¡ ì‚¬ (ê²½ì œì§€/ì¼ê°„ì§€)")
                q = f'{ko_name} "ë¯¸êµ­ ì§„ì¶œ" OR "íˆ¬ì" OR "ê³µì¥"'
                items = fetch_all_korean_investments(q, "ko", "KR")
                for e in items[:7]:
                    with st.container(border=True):
                        st.markdown(f"**[{e.title.split(' - ')[0]}]({e.link})**")
                        st.caption(f"ğŸ“… {e.published[:16]} | {e.source.title}")
                    
            with col_diaspora: # 2. ë¯¸ í˜„ì§€ ë™í¬ ì‹ ë¬¸ (ì• í‹€ëœíƒ€ ì¤‘ì•™ì¼ë³´ ë“±)
                st.caption("ğŸ‡ºğŸ‡¸ ë¯¸ í˜„ì§€ ë™í¬ ì‹ ë¬¸ (í•œì¸ ë‰´ìŠ¤)")
                # ë¯¸êµ­ ë‚´ í•œêµ­ì–´ ì„œë¹„ìŠ¤(gl=US)ë¥¼ ì§‘ì¤‘ ê²€ìƒ‰
                q = f'{ko_name} "íˆ¬ì" OR "ê³µì¥" OR "ì§„ì¶œ"'
                items = fetch_all_korean_investments(q, "ko", "US")
                for e in items[:7]:
                    with st.container(border=True):
                        st.markdown(f"**[{e.title.split(' - ')[0]}]({e.link})**")
                        st.caption(f"ğŸ“… {e.published[:16]} | {e.source.title}")
