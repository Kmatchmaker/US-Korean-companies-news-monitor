import streamlit as st
import feedparser
import urllib.parse
from datetime import datetime

# 1. ëŒ€ìƒ ì£¼ ë° ì‚°ì—…ë³„ í•µì‹¬ í‚¤ì›Œë“œ ì„¤ì •
STATES = {
    "Georgia": "ì¡°ì§€ì•„ (ë™ì›ì˜¤í† Â·ë•ì‹ EPC ë“±)",
    "Alabama": "ì•¨ë¼ë°°ë§ˆ (ì§€ì— ë¹„ì½”ë¦¬ì•„Â·í˜„ëŒ€ì¼ë ‰ ë“±)",
    "Tennessee": "í…Œë„¤ì‹œ (íš¨ì„±ì¤‘ê³µì—…Â·LGì—”ì†”Â·í•œêµ­íƒ€ì´ì–´)",
    "South Carolina": "ì‚¬ìš°ìŠ¤ìºë¡¤ë¼ì´ë‚˜",
    "Florida": "í”Œë¡œë¦¬ë‹¤"
}

st.set_page_config(page_title="2026 éŸ“ ê¸°ì—… ë¯¸êµ­ ì§„ì¶œ ì¸í…”ë¦¬ì „ìŠ¤", layout="wide")
st.title("ğŸšœ 2026ë…„ 2ì›” ë¯¸ ë™ë‚¨ë¶€ éŸ“ ê¸°ì—… ì§„ì¶œÂ·íˆ¬ì ì •ë°€ ë³´ë“œ")
st.markdown("### ğŸ›ï¸ ì£¼ ì •ë¶€ ê³µì‹ ë°œí‘œ(Official) ë° í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ì •ë³´ ìš°ì„  ë¸Œë¦¬í•‘")

# --- ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ë¹„ì¦ˆë‹ˆìŠ¤ ì¤‘ìš”ë„ í•„í„° ì—”ì§„ ---
def fetch_high_priority_news(query, lang, gl):
    # 2026ë…„ 2ì›” ì´í›„ ë°ì´í„° + íˆ¬ì í™•ì¥ í‚¤ì›Œë“œ
    biz_terms = '(investment OR "new plant" OR "announces" OR "expansion" OR "contract")'
    date_filter = "after:2026-02-01"
    
    full_query = f'{query} {biz_terms} {date_filter}'
    encoded_query = urllib.parse.quote(full_query)
    url = f"https://news.google.com/rss/search?q={encoded_query}&hl={lang}&gl={gl}&ceid={gl}:{lang}"
    
    feed = feedparser.parse(url)
    verified = []
    
    # [ë…¸ì´ì¦ˆ ìº”ìŠ¬ëŸ¬] ì‚¬ìš©ìë‹˜ì´ ì§€ì í•˜ì‹  ê³¼ê±° ì‚¬ê±´ì‚¬ê³  í‚¤ì›Œë“œ ì œê±°
    noise_words = ["arrest", "raid", "detain", "investigation", "êµ¬ê¸ˆ", "ë ˆì´ë“œ", "ìˆ˜ì‚¬"]
    
    for entry in feed.entries:
        title = entry.title.lower()
        # 2026ë…„ë„ ë°œí–‰ ê¸°ì‚¬ë§Œ í†µê³¼
        if entry.get('published_parsed') and entry.published_parsed.tm_year == 2026:
            if not any(noise in title for noise in noise_words):
                # ì¤‘ìš”ë„ ê°€ì : ì£¼ ì •ë¶€ ë°œí‘œ(.gov)ê±°ë‚˜ í•µì‹¬ ê¸°ì—…ëª… í¬í•¨ ì‹œ ê°€ì‚°ì 
                priority_score = 0
                if ".gov" in entry.link: priority_score += 10
                if any(target in title for target in ["dongwon", "gmb", "hyosung", "lg", "hankook"]): priority_score += 5
                
                verified.append({"entry": entry, "score": priority_score})
                
    # ì ìˆ˜ ë†’ì€ ìˆœ(ì¤‘ìš”ë„) -> ìµœì‹ ìˆœ ì •ë ¬
    sorted_results = sorted(verified, key=lambda x: (x['score'], x['entry'].published_parsed), reverse=True)
    return [x['entry'] for x in sorted_results]

# --- í™”ë©´ ë ˆì´ì•„ì›ƒ êµ¬ì„± ---
tab_us, tab_kr = st.tabs(["ğŸ‡ºğŸ‡¸ ë¯¸êµ­ í˜„ì§€ ì˜¤í”¼ì…œ (Gov & Biz)", "ğŸ‡°ğŸ‡· í•œêµ­ ì–¸ë¡  & ê³µì‹œ (Press)"])

with tab_us:
    st.info("ğŸ’¡ ì£¼ì§€ì‚¬ì‹¤(.gov) ë³´ë„ìë£Œ ë° ì§€ì—­ ê²½ì œ ë§¤ì²´ ì •ë°€ í•„í„°ë§")
    for en_name, display_name in STATES.items():
        with st.expander(f"ğŸ“ {display_name}", expanded=True):
            col1, col2 = st.columns(2)
            
            with col1:
                st.caption("ğŸ›ï¸ 1. ì£¼ ì •ë¶€ ê³µì‹ ë°œí‘œ (Official Press Release)")
                # site:.gov í•„í„°ë¡œ ì£¼ì§€ì‚¬ ë°œí‘œ ì›ë¬¸ì„ ê°•ì œ ê²€ìƒ‰
                q = f'site:.gov "{en_name}" "South Korea" investment'
                items = fetch_high_priority_news(q, "en-US", "US")
                for e in items[:3]:
                    st.success(f"**[GOV] [{e.title.split(' - ')[0]}]({e.link})**")
                    st.caption(f"ğŸ“… {e.published[:16]}")

            with col2:
                st.caption("ğŸ“° 2. í˜„ì§€ ìœ ë ¥ ê²½ì œì§€ (Business News)")
                q = f'"{en_name}" "South Korea" (Journal OR Chronicle OR News) investment'
                items = fetch_high_priority_news(q, "en-US", "US")
                for e in items[:3]:
                    st.markdown(f"â€¢ [{e.title.split(' - ')[0]}]({e.link})")
                    st.caption(f"ğŸ“… {e.published[:16]} | {e.source.title}")

with tab_kr:
    st.success("ğŸ—ï¸ í•œêµ­ ì£¼ìš” ê²½ì œì§€ ë° ê¸°ì—… ê³µì‹œ ê¸°ë°˜ íˆ¬ì ë³´ë„")
    for en_name, display_name in STATES.items():
        ko_name = display_name.split(" ")[0]
        with st.expander(f"ğŸ“ {ko_name} ({en_name})", expanded=True):
            col_press, col_dia = st.columns(2)
            
            with col_press:
                st.caption("ğŸ—ï¸ 1. í•œêµ­ ì£¼ìš” ì–¸ë¡  (ì¶œì/ìˆ˜ì£¼/ì¦ì„¤)")
                # ì‚¬ìš©ìë‹˜ ìš”ì²­ í‚¤ì›Œë“œ ìµœìš°ì„  ë°°ì¹˜
                q = f'{ko_name} ("ì¶œì" OR "ìˆ˜ì£¼" OR "ì¦ì„¤" OR "ì–‘ì‚°" OR "íˆ¬ì")'
                items = fetch_high_priority_news(q, "ko", "KR")
                for e in items[:5]:
                    st.markdown(f"**[{e.title.split(' - ')[0]}]({e.link})**")
                    st.caption(f"ğŸ“… {e.published[:16]} | {e.source.title}")
                    
            with col_dia:
                st.caption("ğŸ‡ºğŸ‡¸ 2. ë¯¸ í˜„ì§€ ìœ ë ¥ ë™í¬ ì†Œì‹")
                q = f'{ko_name} "íˆ¬ì" OR "ê³µì¥" OR "ì§„ì¶œ"'
                items = fetch_high_priority_news(q, "ko", "US")
                for e in items[:5]:
                    st.markdown(f"â€¢ [{e.title.split(' - ')[0]}]({e.link})")
                    st.caption(f"ğŸ“… {e.published[:16]} | {e.source.title}")
