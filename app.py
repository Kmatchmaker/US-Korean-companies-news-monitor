import streamlit as st
import feedparser
import urllib.parse
from datetime import datetime

# 1. ëŒ€ìƒ ì£¼ ë° ì‚°ì—…êµ° í•µì‹¬ í‚¤ì›Œë“œ ì„¤ì •
STATES = {
    "Alabama": "ì•¨ë¼ë°°ë§ˆ (GMBì½”ë¦¬ì•„ ë“±)",
    "Tennessee": "í…Œë„¤ì‹œ (LGì—”ì†”, í•œêµ­íƒ€ì´ì–´ ë“±)",
    "Georgia": "ì¡°ì§€ì•„ (í˜„ëŒ€ì°¨ í˜‘ë ¥ì‚¬ ë“±)",
    "South Carolina": "ì‚¬ìš°ìŠ¤ìºë¡¤ë¼ì´ë‚˜ (ì‚¼ì„±, ì„¸ë°© ë“±)",
    "Florida": "í”Œë¡œë¦¬ë‹¤"
}

# ì‚¬ìš©ì ì˜ˆì‹œ ê¸°ë°˜ í•µì‹¬ ê¸°ì—…/ì‚°ì—… í‚¤ì›Œë“œ
BIZ_KEYWORDS = "GMB, íš¨ì„±ì¤‘ê³µì—…, í˜„ëŒ€ì¼ë ‰íŠ¸ë¦­, LGì—”ì†”, í•œêµ­íƒ€ì´ì–´, ë³€ì••ê¸°, ë°°í„°ë¦¬, LFP, ì¦ì„¤, ì¶œì"

st.set_page_config(page_title="2026 éŸ“ ê¸°ì—… ë¯¸êµ­ ì§„ì¶œ ì‹¤ì‹œê°„ ë³´ë“œ", layout="wide")
st.title("ğŸ­ 2026ë…„ ë¯¸ ë™ë‚¨ë¶€ í•œêµ­ ê¸°ì—… ì§„ì¶œÂ·íˆ¬ì ì •ë°€ ë³´ë“œ")
st.caption(f"ëŒ€ìƒ ê¸°ì—…/ì‚°ì—…: {BIZ_KEYWORDS}")

def fetch_latest_news(query, lang, gl, period="30d"):
    # 1ì°¨ ì‹œë„: ìµœê·¼ 30ì¼(period) ë‚´ ë°ì´í„°
    # 2ì°¨ ì‹œë„: ë°ì´í„°ê°€ ì—†ìœ¼ë©´ 'after:2025-01-01'ë¡œ ë²”ìœ„ë¥¼ ë„“í˜€ 'ê°€ì¥ ìµœê·¼' ê²ƒ í™•ë³´
    encoded_query = urllib.parse.quote(f"{query} when:{period}")
    url = f"https://news.google.com/rss/search?q={encoded_query}&hl={lang}&gl={gl}&ceid={gl}:{lang}"
    feed = feedparser.parse(url)
    
    # ë§Œì•½ 30ì¼ ë‚´ ë‰´ìŠ¤ê°€ ì—†ìœ¼ë©´ ì „ì²´ ê¸°ê°„ì—ì„œ ê°€ì¥ ìµœê·¼ ê²ƒì„ ê°€ì ¸ì˜¤ë„ë¡ ì¬ì‹œë„
    if not feed.entries and period == "30d":
        encoded_query = urllib.parse.quote(f"{query} after:2025-01-01")
        url = f"https://news.google.com/rss/search?q={encoded_query}&hl={lang}&gl={gl}&ceid={gl}:{lang}"
        feed = feedparser.parse(url)

    # ì¤‘ë³µ ì œê±° ë° ë‚ ì§œìˆœ ì •ë ¬
    seen = set()
    verified = []
    for entry in feed.entries:
        if entry.link not in seen:
            verified.append(entry)
            seen.add(entry.link)
    
    return sorted(verified, key=lambda x: x.get('published_parsed'), reverse=True)

# --- ë³´ë“œ ì„¤ê³„ ---
tab_us, tab_kr = st.tabs(["ğŸ‡ºğŸ‡¸ ë¯¸êµ­ í˜„ì§€ ì˜¤í”¼ì…œ (ì£¼ì •ë¶€/ê²½ì œì§€)", "ğŸ‡°ğŸ‡· í•œêµ­ ì–¸ë¡  ë³´ë„ (ê¸°ì—…ê³µì‹œ/ì£¼ìš”ê²½ì œì§€)"])

with tab_us:
    st.info("ğŸ’¡ ì£¼ ì •ë¶€(Official) ë° í˜„ì§€ ê²½ì œì§€ ë°œ 'ì‹ ê·œ íˆ¬ì/ì¦ì„¤' ì†Œì‹")
    for en_name, display_name in STATES.items():
        with st.expander(f"ğŸ“ {display_name}", expanded=True):
            col1, col2 = st.columns(2)
            
            with col1:
                st.caption("ğŸ›ï¸ ì£¼ ì •ë¶€ ê³µì‹ ë°œí‘œ (site:.gov)")
                # ì£¼ ì •ë¶€ ì‚¬ì´íŠ¸ì—ì„œ í•œêµ­ ê¸°ì—…(South Korea) ê´€ë ¨ íˆ¬ì ë°œí‘œ ê²€ìƒ‰
                q = f'site:.gov "{en_name}" "South Korea" (investment OR factory OR expansion)'
                items = fetch_latest_news(q, "en-US", "US")
                for e in items[:3]:
                    st.markdown(f"â€¢ [{e.title.split(' - ')[0]}]({e.link})  \n  :gray[{e.published[:16]}]")
            
            with col2:
                st.caption("ğŸ“° í˜„ì§€ ê²½ì œ ë§¤ì²´ (Biz Journals ë“±)")
                # ì£¼ë³„ ê¸°ì—…ëª… ë° ì‚°ì—… í‚¤ì›Œë“œ ê²€ìƒ‰
                q = f'"{en_name}" "South Korea" (battery OR transformer OR manufacturing)'
                items = fetch_latest_news(q, "en-US", "US")
                for e in items[:3]:
                    st.markdown(f"â€¢ [{e.title.split(' - ')[0]}]({e.link})  \n  :gray[{e.source.title} | {e.published[:16]}]")

with tab_kr:
    st.success("ğŸ’¡ í•œêµ­ ë‚´ ì£¼ìš” ì–¸ë¡  ë° ê¸°ì—… ê³µì‹œ ê´€ë ¨ ë³´ë„")
    for en_name, display_name in STATES.items():
        ko_name = display_name.split(" ")[0]
        with st.expander(f"ğŸ“ {display_name}", expanded=True):
            col_press, col_dia = st.columns(2)
            
            with col_press:
                st.caption("ğŸ—ï¸ êµ­ë‚´ ì£¼ìš” ê²½ì œì§€ (íˆ¬ì/ê³µì‹œ/ì¦ì„¤)")
                # ì‚¬ìš©ì ì˜ˆì‹œ í‚¤ì›Œë“œë¥¼ ë°˜ì˜í•œ ê²€ìƒ‰
                q = f'{ko_name} ("ì¶œì" OR "ì¦ì„¤" OR "ì–‘ì‚°" OR "ìˆ˜ì£¼")'
                items = fetch_latest_news(q, "ko", "KR")
                for e in items[:5]:
                    st.markdown(f"â€¢ [{e.title.split(' - ')[0]}]({e.link})  \n  :gray[{e.source.title} | {e.published[:16]}]")
                    
            with col_dia:
                st.caption("ğŸ‡ºğŸ‡¸ ë¯¸ í˜„ì§€ ë™í¬ ì†Œì‹ (í•œì¸ ê²½ì œ)")
                q = f'{ko_name} "íˆ¬ì" OR "ê³µì¥" OR "ì§„ì¶œ"'
                items = fetch_latest_news(q, "ko", "US")
                for e in items[:5]:
                    st.markdown(f"â€¢ [{e.title.split(' - ')[0]}]({e.link})  \n  :gray[{e.source.title} | {e.published[:16]}]")
